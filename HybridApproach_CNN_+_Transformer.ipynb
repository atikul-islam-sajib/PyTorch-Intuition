{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nIxvtMIP1Pr",
        "outputId": "1a2fc98f-c803-414c-89d1-c577152b16c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.1525\n",
            "Epoch [2/5], Loss: 0.0520\n",
            "Epoch [3/5], Loss: 0.0360\n",
            "Epoch [4/5], Loss: 0.0307\n",
            "Epoch [5/5], Loss: 0.0258\n",
            "Test Accuracy of the model on the 10000 test images: 98.86%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the Hybrid Model (from the previous step)\n",
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, pool_size=2):\n",
        "        super(CNNBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.pool = nn.MaxPool2d(pool_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        return x\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_hidden_dim, dropout=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_hidden_dim, embed_dim),\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_output, _ = self.attention(x, x, x)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.ff(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class MNISTHybridModel(nn.Module):\n",
        "    def __init__(self, num_classes=10, embed_dim=64, num_heads=2, ff_hidden_dim=128, num_transformer_layers=1):\n",
        "        super(MNISTHybridModel, self).__init__()\n",
        "\n",
        "        # CNN feature extractor\n",
        "        self.cnn = nn.Sequential(\n",
        "            CNNBlock(1, 32),   # 28x28 -> 14x14\n",
        "            CNNBlock(32, 64),  # 14x14 -> 7x7\n",
        "        )\n",
        "\n",
        "        # Linear projection to transformer input\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(64 * 7 * 7, embed_dim)  # 7x7 is the size after two poolings\n",
        "\n",
        "        # Transformer layers\n",
        "        self.transformer_layers = nn.ModuleList(\n",
        "            [TransformerBlock(embed_dim, num_heads, ff_hidden_dim) for _ in range(num_transformer_layers)]\n",
        "        )\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features using CNN\n",
        "        x = self.cnn(x)  # Shape: (batch_size, 64, 7, 7)\n",
        "\n",
        "        # Flatten and project to transformer input\n",
        "        x = self.flatten(x)  # Shape: (batch_size, 64 * 7 * 7)\n",
        "        x = self.fc(x)  # Shape: (batch_size, embed_dim)\n",
        "\n",
        "        # Prepare for transformer input: (sequence_length, batch_size, embed_dim)\n",
        "        x = x.unsqueeze(0)  # Adding a sequence dimension: Shape: (1, batch_size, embed_dim)\n",
        "\n",
        "        # Apply transformer layers\n",
        "        for transformer_layer in self.transformer_layers:\n",
        "            x = transformer_layer(x)\n",
        "\n",
        "        # Classification\n",
        "        x = x.squeeze(0)  # Remove sequence dimension\n",
        "        x = self.classifier(x)  # Shape: (batch_size, num_classes)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Define Hyperparameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "\n",
        "# Load MNIST Data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = MNISTHybridModel(num_classes=10, embed_dim=64, num_heads=2, ff_hidden_dim=128, num_transformer_layers=1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
        "\n",
        "# Testing the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Accuracy of the model on the 10000 test images: {100 * correct / total:.2f}%')\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'mnist_hybrid_model.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can combine Convolutional Neural Networks (CNNs) with transformer layers. In such models, the CNN extracts feature maps from the image, and then multihead attention is applied to these feature maps."
      ],
      "metadata": {
        "id": "MAIwQObfQ9IV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hv1FYvbMQA82"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}